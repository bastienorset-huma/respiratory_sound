{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import IPython.display as ipd\n",
    "import warnings\n",
    "import librosa\n",
    "import librosa.display\n",
    "import librosa.feature\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import utils\n",
    "\n",
    "import processing\n",
    "import event_manager\n",
    "import model_training\n",
    "import epoching\n",
    "\n",
    "import pickle\n",
    "import model_prepare\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_folder = '../../data/ICBHI_final_database'\n",
    "list_audio_files = processing.get_list_recording(audio_folder)\n",
    "print('Found {} recording files'.format(len(list_audio_files)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 22050\n",
    "n_fft =2048\n",
    "hop_length=512\n",
    "win_len=1\n",
    "win_shift=0.250\n",
    "df_label_list=list()\n",
    "epochs_list = []\n",
    "for audio_file in tqdm(list_audio_files):\n",
    "    try:\n",
    "        data_file = processing.load_file_from_recording_name(audio_folder,audio_file)\n",
    "        data_filtered,df_label = processing.preprocess_data(data_file,fs=fs, annotations='event')\n",
    "        df_label = event_manager.fill_gap_event_frame(df_label,data_filtered)\n",
    "        df_label = event_manager.segment_event_annotation(data_filtered,win_len=win_len,win_shift=win_shift,threshold_class=[1,None,None])\n",
    "        df_label['file']=audio_file\n",
    "        df_label = model_prepare.select_nsample_normal(df_label)\n",
    "        epochs_ = epoching.get_epoching_from_label_data(data_filtered,df_label,constant_values=0)\n",
    "        X,f = processing.apply_mel_on_epochs(epochs_,n_fft=n_fft,\n",
    "                                             hop_length=hop_length,\n",
    "                                             fs=data_filtered['fs'])     \n",
    "        epochs_list.append(X)\n",
    "        df_label_list.append(df_label)\n",
    "    except:\n",
    "        print(audio_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,df_all_label = model_prepare.prepare_data_time_for_modeling(epochs_list,df_label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "with open('../../data/data_model/data_nothreshold_win1s_sftf.pkl','wb') as f:\n",
    "    pickle.dump(\n",
    "        {\n",
    "        'feature': X,\n",
    "        'label':df_all_label,\n",
    "        },f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "740509af84ee3128d88333a1002968296ddbc89ee8b431d0c0cb3d6651593e8e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
